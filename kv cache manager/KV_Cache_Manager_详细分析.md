# KV Cache Manager è¯¦ç»†åˆ†ææ–‡æ¡£

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [ä¸»å‡½æ•°å®ç°è¯¦è§£](#ä¸»å‡½æ•°å®ç°è¯¦è§£)
3. [æ ¸å¿ƒç»„ä»¶è¯¦è§£](#æ ¸å¿ƒç»„ä»¶è¯¦è§£)
4. [å…³é”®å‡½æ•°è¯¦è§£](#å…³é”®å‡½æ•°è¯¦è§£)
5. [æ¶æ„å›¾](#æ¶æ„å›¾)
6. [ç±»å›¾](#ç±»å›¾)
7. [æ€»ç»“](#æ€»ç»“)

---

## æ¦‚è¿°

**KV Cache Manager** æ˜¯ AIBrix KV Cache Offloading Framework çš„æ ¸å¿ƒç»„ä»¶ï¼Œè´Ÿè´£ç®¡ç† KV ç¼“å­˜çš„å­˜å‚¨ã€æ£€ç´¢ã€åˆ†é…å’Œå¸è½½æ“ä½œã€‚å®ƒé‡‡ç”¨**ä¸¤çº§ç¼“å­˜æ¶æ„**ï¼ˆL1 æœ¬åœ°ç¼“å­˜ + L2 è¿œç¨‹ç¼“å­˜ï¼‰ï¼Œæ”¯æŒå¤šç§åç«¯å­˜å‚¨å’Œé©±é€ç­–ç•¥ã€‚

---

## ä¸»å‡½æ•°å®ç°è¯¦è§£

### 1. `BaseKVCacheManager.__init__()` - åˆå§‹åŒ–å‡½æ•°

è¿™æ˜¯ KV Cache Manager çš„æ ¸å¿ƒåˆå§‹åŒ–å‡½æ•°ï¼Œè´Ÿè´£è®¾ç½®æ‰€æœ‰ç»„ä»¶ã€‚

```python
def __init__(self, config: KVCacheConfig) -> None:
```

#### é€è¡Œä»£ç è§£é‡Š

**ç¬¬ 599 è¡Œï¼šè°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–**
```python
KVCacheManager.__init__(self, config)
```
- è°ƒç”¨æŠ½è±¡åŸºç±» `KVCacheManager` çš„åˆå§‹åŒ–
- è®¾ç½®åŸºç¡€çš„ block è§„æ ¼ä¿¡æ¯ï¼ˆblock_spec, block_shape, block_dtype ç­‰ï¼‰

**ç¬¬ 601-610 è¡Œï¼šåˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶å˜é‡**
```python
self._l1_cache: L1Cache | None = None
self._l2_cache: L2Cache | None = None
self._executor: Executor | None = None
self._event_loop: asyncio.AbstractEventLoop | None = None
self._thread: threading.Thread | None = None
self._l2_inflight_writes: int = 0
self._l2_inflight_quota: int = 0
self._allocator: TensorPoolAllocator | None = None
self._metrics: KVCacheMetrics | None = None
self._ms: MetaService | None = None
```
- `_l1_cache`: L1 æœ¬åœ°ç¼“å­˜ï¼ˆCPU/GPU å†…å­˜ï¼‰
- `_l2_cache`: L2 è¿œç¨‹ç¼“å­˜ï¼ˆRocksDB/InfiniStore ç­‰ï¼‰
- `_executor`: çº¿ç¨‹æ± æ‰§è¡Œå™¨ï¼Œç”¨äºå¼‚æ­¥ L2 æ“ä½œ
- `_event_loop`: å¼‚æ­¥äº‹ä»¶å¾ªç¯ï¼Œå¤„ç† L2 ç¼“å­˜çš„å¼‚æ­¥æ“ä½œ
- `_thread`: è¿è¡Œäº‹ä»¶å¾ªç¯çš„çº¿ç¨‹
- `_l2_inflight_writes`: å½“å‰æ­£åœ¨è¿›è¡Œçš„ L2 å†™å…¥æ•°é‡
- `_l2_inflight_quota`: L2 å†™å…¥çš„æœ€å¤§å¹¶å‘é…é¢
- `_allocator`: å¼ é‡æ± åˆ†é…å™¨ï¼Œç®¡ç†å†…å­˜åˆ†é…
- `_metrics`: æ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨
- `_ms`: å…ƒæ•°æ®æœåŠ¡ï¼ˆç”¨äºåˆ†å¸ƒå¼åœºæ™¯ï¼‰

**ç¬¬ 612-613 è¡Œï¼šåˆå§‹åŒ–åŒæ­¥åŸè¯­**
```python
self._lock = threading.Lock()
self._infight_cv = threading.Condition(self._lock)
```
- `_lock`: ä¿æŠ¤å…±äº«çŠ¶æ€çš„äº’æ–¥é”
- `_infight_cv`: æ¡ä»¶å˜é‡ï¼Œç”¨äºç­‰å¾… L2 å†™å…¥å®Œæˆ

**ç¬¬ 615-620 è¡Œï¼šé…ç½®é˜ˆå€¼å‚æ•°**
```python
self._double_get_threshold: Tuple[int, float] = (
    envs.AIBRIX_KV_CACHE_OL_DOUBLE_GET_THRESHOLD
)
self._l2_cache_per_token_timeout_ms: int = (
    envs.AIBRIX_KV_CACHE_OL_L2_CACHE_PER_TOKEN_TIMEOUT_MS
)
```
- `_double_get_threshold`: å†³å®šæ˜¯å¦åŒæ—¶æŸ¥è¯¢ L1 å’Œ L2 çš„é˜ˆå€¼ï¼ˆå—æ•°é‡æˆ–æ¯”ä¾‹ï¼‰
- `_l2_cache_per_token_timeout_ms`: L2 ç¼“å­˜æ¯ä¸ª token çš„è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰

**ç¬¬ 622-658 è¡Œï¼šé…ç½® chunk_size å’Œ max_seq_len**
```python
self._chunk_size: int = envs.AIBRIX_KV_CACHE_OL_CHUNK_SIZE
self._max_seq_len: int = envs.AIBRIX_KV_CACHE_OL_MAX_SEQ_LEN
if self._max_seq_len > 0:
    max_seq_len = round_up(self._max_seq_len, self.block_ntokens)
    # ... å¯¹é½åˆ° block_ntokens çš„å€æ•°
    self._max_seq_len = max_seq_len

if self._chunk_size % self.block_ntokens != 0:
    # å¯¹é½åˆ° block_ntokens çš„å€æ•°
    self._chunk_size = (
        self._chunk_size - self._chunk_size % self.block_ntokens
    )

if self._chunk_size < 4 * self.block_ntokens:
    # ç¡®ä¿ chunk_size è‡³å°‘æ˜¯ 4 ä¸ª block
    self._chunk_size = 4 * self.block_ntokens
```
- `_chunk_size`: ç¼“å­˜æ“ä½œçš„åˆ†å—å¤§å°ï¼Œå¿…é¡»æ˜¯ block_ntokens çš„å€æ•°
- `_max_seq_len`: æœ€å¤§åºåˆ—é•¿åº¦é™åˆ¶ï¼Œç”¨äºé˜²æ­¢è¿‡é•¿çš„åºåˆ—å ç”¨è¿‡å¤šç¼“å­˜

**ç¬¬ 660-664 è¡Œï¼šé…ç½®è®¾å¤‡ç±»å‹å’Œå†…å­˜å›ºå®š**
```python
device: str = envs.AIBRIX_KV_CACHE_OL_DEVICE
pin_memory: bool = False
if not TESTING_DISABLE_PIN_MEMORY:
    pin_memory = device == "cpu"
```
- `device`: ç¼“å­˜å­˜å‚¨è®¾å¤‡ï¼ˆ"cpu" æˆ– "cuda"ï¼‰
- `pin_memory`: æ˜¯å¦å›ºå®šå†…å­˜ï¼ˆCPU è®¾å¤‡æ—¶å¯ç”¨ï¼ŒåŠ é€Ÿ GPU ä¼ è¾“ï¼‰

**ç¬¬ 666-671 è¡Œï¼šæ£€æŸ¥ç¼“å­˜é…ç½®**
```python
enable_l1: bool = envs.AIBRIX_KV_CACHE_OL_L1_CACHE_ENABLED
enable_l2: bool = len(envs.AIBRIX_KV_CACHE_OL_L2_CACHE_BACKEND) > 0

assert enable_l1 or enable_l2, (
    "At least one cache service must be enabled."
)
```
- è‡³å°‘éœ€è¦å¯ç”¨ L1 æˆ– L2 ä¸­çš„ä¸€ä¸ªç¼“å­˜å±‚

**ç¬¬ 673-689 è¡Œï¼šåˆå§‹åŒ–æŒ‡æ ‡æ”¶é›†å™¨**
```python
capacity_nbytes: int = int(
    envs.AIBRIX_KV_CACHE_OL_L1_CACHE_CAPACITY_GB * 1024**3
)
enable_time_measurement = (
    envs.AIBRIX_KV_CACHE_OL_TIME_MEASUREMENT_ENABLED
)
enable_breakdown_measurement = (
    envs.AIBRIX_KV_CACHE_OL_BREAKDOWN_MEASUREMENT_ENABLED
)
self._metrics = KVCacheMetrics(
    block_ntokens=self.block_ntokens,
    capacity_nbytes=capacity_nbytes,
    enable_l1=enable_l1,
    enable_l2=enable_l2,
    enable_time_measurement=enable_time_measurement,
    enable_breakdown_measurement=enable_breakdown_measurement,
)
```
- åˆ›å»ºæ€§èƒ½æŒ‡æ ‡æ”¶é›†å™¨ï¼Œç”¨äºç›‘æ§ç¼“å­˜å‘½ä¸­ç‡ã€å»¶è¿Ÿç­‰

**ç¬¬ 691-696 è¡Œï¼šåˆå§‹åŒ–å…ƒæ•°æ®æœåŠ¡**
```python
ms_backend: str = envs.AIBRIX_KV_CACHE_OL_META_SERVICE_BACKEND
if len(ms_backend) > 0:
    self._ms = MetaService.create(ms_backend)
    status = self._ms.open()
    status.raise_if_not_ok()
    logger.info(f"Using meta service backend: {self._ms.name}")
```
- å¦‚æœé…ç½®äº†å…ƒæ•°æ®æœåŠ¡åç«¯ï¼ˆå¦‚ Redisï¼‰ï¼Œåˆ™åˆå§‹åŒ–å¹¶æ‰“å¼€è¿æ¥

**ç¬¬ 698-700 è¡Œï¼šåˆå§‹åŒ– MeasurableBase**
```python
assert self._metrics is not None
MeasurableBase.__init__(self, self._metrics.mgr)
```
- åˆå§‹åŒ–å¯æµ‹é‡åŸºç±»ï¼Œç”¨äºæ€§èƒ½è¿½è¸ª

**ç¬¬ 702-749 è¡Œï¼šåˆå§‹åŒ–å†…å­˜åˆ†é…å™¨**
```python
allocator_capacity_nbytes: int = 0

if enable_l1:
    allocator_capacity_nbytes += capacity_nbytes

if enable_l2:
    self._l2_inflight_quota = (
        envs.AIBRIX_KV_CACHE_OL_L2_CACHE_INGESTION_MAX_INFLIGHT_TOKENS
        // self.block_ntokens
    )
    # ... è®¡ç®— L2 ç¼“å­˜æ‰€éœ€çš„å†…å­˜å®¹é‡
    allocator_capacity_nbytes += more_capacity_nbytes

self._allocator = TensorPoolAllocator.create(
    capacity_nbytes=allocator_capacity_nbytes,
    device=device,
    pin_memory=pin_memory,
)
```
- è®¡ç®—åˆ†é…å™¨æ€»å®¹é‡ï¼šL1 å®¹é‡ + L2 å¼‚æ­¥æ“ä½œæ‰€éœ€å®¹é‡
- åˆ›å»ºå¼ é‡æ± åˆ†é…å™¨ï¼Œç»Ÿä¸€ç®¡ç†å†…å­˜åˆ†é…

**ç¬¬ 751-764 è¡Œï¼šåˆå§‹åŒ– L1 ç¼“å­˜**
```python
if enable_l1:
    eviction_policy: str = (
        envs.AIBRIX_KV_CACHE_OL_L1_CACHE_EVICTION_POLICY
    )

    self._l1_cache = L1Cache(
        eviction_policy,
        capacity_nbytes,
        self._allocator,
        self.block_spec,
        metrics=self._metrics.l1,
        multi_threaded=self.config.multi_threaded,
    )
```
- åˆ›å»º L1 ç¼“å­˜å®ä¾‹ï¼Œæ”¯æŒ LRU/FIFO/S3FIFO ç­‰é©±é€ç­–ç•¥

**ç¬¬ 766-798 è¡Œï¼šåˆå§‹åŒ– L2 ç¼“å­˜**
```python
if enable_l2:
    backend_name: str = envs.AIBRIX_KV_CACHE_OL_L2_CACHE_BACKEND
    namespace: str = envs.AIBRIX_KV_CACHE_OL_L2_CACHE_NAMESPACE
    ingestion_type: str = (
        envs.AIBRIX_KV_CACHE_OL_L2_CACHE_INGESTION_TYPE
    )
    op_batch: int = envs.AIBRIX_KV_CACHE_OL_L2_CACHE_OP_BATCH
    self._executor = ThreadPoolExecutor(
        envs.AIBRIX_KV_CACHE_OL_L2_CACHE_NUM_ASYNC_WORKERS,
        thread_name_prefix="l2_cache_",
    )

    placement_policy = envs.AIBRIX_KV_CACHE_OL_L2_CACHE_PLACEMENT_POLICY
    refresh_interval_s = (
        envs.AIBRIX_KV_CACHE_OL_META_SERVICE_REFRESH_INTERVAL_S
    )
    key_builder = KeyBuilder.create(
        envs.AIBRIX_KV_CACHE_OL_L2_CACHE_KEY_BUILDER,
        block_size=self.block_ntokens,
    )
    self._l2_cache = L2Cache(
        backend_name=backend_name,
        placement_policy=placement_policy,
        namespace=namespace,
        block_spec=self.block_spec,
        executor=self._executor,
        refresh_interval_s=refresh_interval_s,
        op_batch=op_batch,
        metrics=self._metrics.l2,
        meta_service=self._ms,
        key_builder=key_builder,
    )
```
- åˆ›å»ºçº¿ç¨‹æ± æ‰§è¡Œå™¨
- åˆ›å»ºé”®æ„å»ºå™¨ï¼ˆç”¨äºç”Ÿæˆç¼“å­˜é”®ï¼‰
- åˆ›å»º L2 ç¼“å­˜å®ä¾‹ï¼Œè¿æ¥åˆ°åç«¯å­˜å‚¨ï¼ˆRocksDB/InfiniStore ç­‰ï¼‰

**ç¬¬ 800-805 è¡Œï¼šå¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯**
```python
self._event_loop = asyncio.new_event_loop()
self._thread = threading.Thread(
    target=self._event_loop.run_forever, daemon=True
)
self._thread.start()
```
- åˆ›å»ºç‹¬ç«‹çš„å¼‚æ­¥äº‹ä»¶å¾ªç¯
- åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œï¼Œå¤„ç† L2 ç¼“å­˜çš„å¼‚æ­¥æ“ä½œ

**ç¬¬ 807-821 è¡Œï¼šæ‰“å¼€ L2 ç¼“å­˜å¹¶æ³¨å†Œå†…å­˜å—**
```python
status = self._l2_cache.open()
status.raise_if_not_ok()

if self._l2_cache._backend.feature.rdma:
    reg_status = self._l2_cache.register_slabs(
        self._allocator.slabs
    )
    # ... é”™è¯¯å¤„ç†
```
- æ‰“å¼€ L2 ç¼“å­˜è¿æ¥
- å¦‚æœåç«¯æ”¯æŒ RDMAï¼Œæ³¨å†Œå†…å­˜å—ä»¥å¯ç”¨é›¶æ‹·è´

**ç¬¬ 823-836 è¡Œï¼šæ³¨å†Œ L1 åˆ° L2 çš„å›è°ƒå‡½æ•°**
```python
if self._l1_cache is not None:
    if ingestion_type == "HOT":
        self._l1_cache.set_on_hot_access_callback(
            self._l2_ingestion_callback
        )
    elif ingestion_type == "ALL":
        self._l1_cache.set_on_put_callback(
            self._l2_ingestion_callback
        )
    else:
        self._l1_cache.set_on_evict_callback(
            self._l2_ingestion_callback
        )
```
- æ ¹æ® `ingestion_type` é…ç½®ï¼Œè®¾ç½® L1 åˆ° L2 çš„æ•°æ®åŒæ­¥ç­–ç•¥ï¼š
  - `HOT`: åªæœ‰çƒ­æ•°æ®ï¼ˆé¢‘ç¹è®¿é—®ï¼‰æ‰åŒæ­¥åˆ° L2
  - `ALL`: æ‰€æœ‰æ•°æ®éƒ½åŒæ­¥åˆ° L2
  - å…¶ä»–ï¼ˆé»˜è®¤ï¼‰: åªæœ‰è¢«é©±é€çš„æ•°æ®æ‰åŒæ­¥åˆ° L2

**ç¬¬ 838-842 è¡Œï¼šæœ€ç»ˆéªŒè¯**
```python
assert self._l1_cache is not None or self._l2_cache is not None, (
    "At least one cache service must be enabled."
)

logger.info("%s is initialized", self)
```
- ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªç¼“å­˜å±‚å·²å¯ç”¨
- è®°å½•åˆå§‹åŒ–å®Œæˆæ—¥å¿—

---

### 2. `acquire()` - è·å–ç¼“å­˜æ•°æ®

è¿™æ˜¯è·å– KV ç¼“å­˜çš„æ ¸å¿ƒæ–¹æ³•ã€‚

```python
@nvtx_range("acquire", "KVCacheManager")
@MeasurableBase.measure(MetricRecorder.OP.ACQUIRE)
def acquire(self, *args, **kwargs) -> Status[Tuple[int, KVCacheHandle]]:
```

#### é€è¡Œä»£ç è§£é‡Š

**ç¬¬ 1076 è¡Œï¼šè§£æå‚æ•°**
```python
prefix, query, _ = parse_kvcache_api_args(*args, **kwargs)
```
- è§£æè¾“å…¥å‚æ•°ï¼Œæå– prefixï¼ˆå‰ç¼€ tokensï¼‰å’Œ queryï¼ˆæŸ¥è¯¢ tokensï¼‰

**ç¬¬ 1078-1082 è¡Œï¼šéªŒè¯ block å¤§å°å…¼å®¹æ€§**
```python
if not isinstance(query, TokenListView):
    assert self.block_ntokens % query.block_ntokens == 0, (
        f"kvcache's block size ({self.block_ntokens}) must be multiple "
        f"of cache key's block_ntokens ({query.block_ntokens})"
    )
```
- å¦‚æœä½¿ç”¨ BlockHashes è€Œä¸æ˜¯ TokenListViewï¼Œç¡®ä¿ block å¤§å°å…¼å®¹

**ç¬¬ 1084-1086 è¡Œï¼šè°ƒç”¨å†…éƒ¨å®ç°**
```python
status = self._acquire_impl(prefix, query)
if not status.is_ok():
    return Status(status)
```
- è°ƒç”¨å†…éƒ¨å®ç°æ–¹æ³•è·å–ç¼“å­˜æ•°æ®
- å¦‚æœå¤±è´¥ï¼Œç›´æ¥è¿”å›é”™è¯¯çŠ¶æ€

**ç¬¬ 1088-1098 è¡Œï¼šæ„é€ è¿”å›ç»“æœ**
```python
value = status.get()
return Status.ok(
    (
        len(value) * self.block_ntokens,
        MemoryRegionKVCacheHandle(
            self.block_dtype,
            self.block_shape,
            value,  # type: ignore
        ),
    )
)
```
- è®¡ç®—è·å–åˆ°çš„ token æ•°é‡ï¼ˆå—æ•° Ã— æ¯å— token æ•°ï¼‰
- åˆ›å»º `MemoryRegionKVCacheHandle` åŒ…è£…å†…å­˜åŒºåŸŸ
- è¿”å› (token_count, handle) å…ƒç»„

---

### 3. `_acquire_impl()` - å†…éƒ¨è·å–å®ç°

è¿™æ˜¯å®é™…æ‰§è¡Œç¼“å­˜è·å–çš„é€»è¾‘ã€‚

```python
def _acquire_impl(
    self,
    prefix: KVCacheKeyTypes | None,
    query: KVCacheKeyTypes,
    output_mrs: Sequence[MemoryRegion] | None = None,
) -> Status[Sequence[MemoryRegion]]:
```

#### å…³é”®é€»è¾‘æµç¨‹

**æ­¥éª¤ 1ï¼šéªŒè¯å‰ç¼€å¯¹é½ï¼ˆç¬¬ 1254-1255 è¡Œï¼‰**
```python
if prefix is not None and len(prefix) % self.block_ntokens != 0:
    return Status(StatusCodes.INVALID)
```
- ç¡®ä¿å‰ç¼€é•¿åº¦æ˜¯ block å¤§å°çš„å€æ•°

**æ­¥éª¤ 2ï¼šè®¡ç®—éœ€è¦çš„å—æ•°ï¼ˆç¬¬ 1257-1262 è¡Œï¼‰**
```python
if output_mrs is not None:
    num_blocks = len(output_mrs)
    ntokens_to_get = num_blocks * self.block_ntokens
    query = query[:ntokens_to_get]
else:
    num_blocks = len(query) // self.block_ntokens
```
- å¦‚æœæä¾›äº†è¾“å‡ºå†…å­˜åŒºåŸŸï¼Œä½¿ç”¨å…¶æ•°é‡
- å¦åˆ™æ ¹æ® query é•¿åº¦è®¡ç®—å—æ•°

**æ­¥éª¤ 3ï¼šå°è¯•ä» L1 ç¼“å­˜è·å–ï¼ˆç¬¬ 1274-1295 è¡Œï¼‰**
```python
if self._l1_cache is not None:
    l1_status = self._l1_cache.acquire(prefix, query)
    fetched_mrs = list(l1_status.get()) if l1_status.is_ok() else []
    num_fetched_blocks = len(fetched_mrs)
    num_missing_blocks = num_blocks - num_fetched_blocks

    if num_missing_blocks == 0 or not self._use_double_get(
        num_missing_blocks, num_blocks
    ):
        # L1 å®Œå…¨å‘½ä¸­ï¼Œæˆ–ä¸éœ€è¦æŸ¥è¯¢ L2ï¼Œç›´æ¥è¿”å›
        if not l1_status.is_ok():
            return l1_status
        # ... å¤„ç†è¾“å‡ºå†…å­˜åŒºåŸŸ
        return l1_status
```
- é¦–å…ˆå°è¯•ä» L1 ç¼“å­˜è·å–
- å¦‚æœå®Œå…¨å‘½ä¸­æˆ–ä¸éœ€è¦æŸ¥è¯¢ L2ï¼Œç›´æ¥è¿”å›

**æ­¥éª¤ 4ï¼šä» L2 ç¼“å­˜è·å–ç¼ºå¤±çš„æ•°æ®ï¼ˆç¬¬ 1297-1335 è¡Œï¼‰**
```python
assert self._l2_cache is not None
# è®¡ç®—å½“å‰å‰ç¼€ï¼ˆåŒ…å«å·²è·å–çš„éƒ¨åˆ†ï¼‰
if prefix is not None:
    prefix_curr = (
        prefix + query[: num_fetched_blocks * self.block_ntokens]
    )
else:
    prefix_curr = query[: num_fetched_blocks * self.block_ntokens]
tokens_curr = query[num_fetched_blocks * self.block_ntokens :]

# è®¡ç®—è¶…æ—¶æ—¶é—´
timeout_s = (
    num_missing_blocks
    * self.block_ntokens
    * self._l2_cache_per_token_timeout_ms
) / 1000

# åˆ†é…æˆ–ä½¿ç”¨æä¾›çš„å†…å­˜åŒºåŸŸ
if output_mrs is None:
    status = self.allocate_for(prefix_curr, tokens_curr)
    # ...
    mrs: List[MemoryRegion] = list(status.get().memory_regions)
else:
    mrs: List[MemoryRegion] = list(output_mrs[num_fetched_blocks:])

# å¼‚æ­¥ä» L2 è·å–
future = asyncio.run_coroutine_threadsafe(
    self._l2_cache.get(prefix_curr, tokens_curr, mrs), self._event_loop
)
get_status = future.result(timeout=timeout_s)
```
- è®¡ç®—å½“å‰å‰ç¼€ï¼ˆåŒ…å«å·²ä» L1 è·å–çš„éƒ¨åˆ†ï¼‰
- åˆ†é…å†…å­˜åŒºåŸŸæˆ–ä½¿ç”¨æä¾›çš„åŒºåŸŸ
- å¼‚æ­¥ä» L2 ç¼“å­˜è·å–æ•°æ®ï¼Œå¸¦è¶…æ—¶æ§åˆ¶

**æ­¥éª¤ 5ï¼šå°† L2 æ•°æ®å†™å…¥ L1 ç¼“å­˜ï¼ˆç¬¬ 1337-1360 è¡Œï¼‰**
```python
if self._l1_cache is not None:
    put_tokens_curr = tokens_curr[
        : len(l2_fetched_mrs) * self.block_ntokens
    ]
    # å°†è·å–çš„æ•°æ®æ”¾å…¥ L1 ç¼“å­˜ï¼Œä»¥ä¾¿ä¸‹æ¬¡å¿«é€Ÿè®¿é—®
    put_status = self._l1_cache.put(
        prefix_curr, put_tokens_curr, l2_fetched_mrs
    )
```
- å°†ä» L2 è·å–çš„æ•°æ®å†™å…¥ L1 ç¼“å­˜ï¼Œæé«˜åç»­è®¿é—®é€Ÿåº¦

**æ­¥éª¤ 6ï¼šé”™è¯¯å¤„ç†å’Œèµ„æºé‡Šæ”¾ï¼ˆç¬¬ 1366-1391 è¡Œï¼‰**
```python
except asyncio.CancelledError:
    # å–æ¶ˆæ“ä½œ
    return Status(StatusCodes.CANCELLED)
except asyncio.TimeoutError:
    # è¶…æ—¶
    return Status(StatusCodes.TIMEOUT)
except Exception as e:
    # å…¶ä»–é”™è¯¯
    return Status(StatusCodes.ERROR, e)
finally:
    if output_mrs is None:
        self._release(mrs)  # é‡Šæ”¾æœªä½¿ç”¨çš„å†…å­˜åŒºåŸŸ
    if not future.done():
        future.cancel()  # å–æ¶ˆæœªå®Œæˆçš„å¼‚æ­¥æ“ä½œ
```
- å¤„ç†å„ç§å¼‚å¸¸æƒ…å†µ
- ç¡®ä¿èµ„æºæ­£ç¡®é‡Šæ”¾

---

### 4. `put()` - å†™å…¥ç¼“å­˜æ•°æ®

è¿™æ˜¯å†™å…¥ KV ç¼“å­˜çš„æ ¸å¿ƒæ–¹æ³•ã€‚

```python
@nvtx_range("put", "KVCacheManager")
@MeasurableBase.measure(MetricRecorder.OP.PUT)
def put(self, *args, **kwargs) -> Status[int]:
```

#### é€è¡Œä»£ç è§£é‡Š

**ç¬¬ 1469 è¡Œï¼šè§£æå‚æ•°**
```python
prefix, query, kv_tensors = parse_kvcache_api_args(*args, **kwargs)
```

**ç¬¬ 1471-1475 è¡Œï¼šéªŒè¯ block å¤§å°**
```python
if not isinstance(query, TokenListView):
    assert self.block_ntokens % query.block_ntokens == 0, (
        f"kvcache's block size ({self.block_ntokens}) must be multiple "
        f"of cache key's block_ntokens ({query.block_ntokens})"
    )
```

**ç¬¬ 1477-1486 è¡Œï¼šéªŒè¯å‰ç¼€å¯¹é½**
```python
pref_len = len(prefix) if prefix is not None else 0
if pref_len % self.block_ntokens != 0:
    kv_tensors.release()
    return Status(
        StatusCodes.INVALID,
        (
            f"Prefix length {pref_len} is not aligned to block size "
            f"{self.block_ntokens}."
        ),
    )
```
- å‰ç¼€é•¿åº¦å¿…é¡»æ˜¯ block å¤§å°çš„å€æ•°
- å¦‚æœä¸æ»¡è¶³ï¼Œé‡Šæ”¾èµ„æºå¹¶è¿”å›é”™è¯¯

**ç¬¬ 1488-1503 è¡Œï¼šåºåˆ—é•¿åº¦é™åˆ¶**
```python
if self._max_seq_len > 0:
    if pref_len >= self._max_seq_len:
        kv_tensors.release()
        return Status(StatusCodes.DENIED, "Sequence too long")
    elif pref_len + len(query) > self._max_seq_len:
        token_len = round_down(
            self._max_seq_len - pref_len,
            self.block_ntokens,
        )
        if token_len == 0:
            kv_tensors.release()
            return Status.ok(0)
        # æˆªæ–­ query å’Œ kv_tensors
        query = query[:token_len]
        kv_tensors.truncate(token_len // self.block_ntokens)
```
- å¦‚æœè®¾ç½®äº†æœ€å¤§åºåˆ—é•¿åº¦é™åˆ¶ï¼Œæ£€æŸ¥å¹¶æˆªæ–­è¶…é•¿åºåˆ—

**ç¬¬ 1505-1506 è¡Œï¼šGDR æ”¯æŒæ£€æŸ¥**
```python
if isinstance(kv_tensors, GDRKVCacheHandle):
    assert self.feature.gdr_put, "Does not support GDR put"
```
- å¦‚æœä½¿ç”¨ GPU Direct Readï¼Œç¡®ä¿åç«¯æ”¯æŒ

**ç¬¬ 1511-1527 è¡Œï¼šå†™å…¥ L1 ç¼“å­˜**
```python
if self._l1_cache is not None:
    if kv_tensors.memory_region_type is ManagedMemoryRegion:
        mrs = kv_tensors.memory_regions
        status = self._l1_cache.put(prefix, query, mrs)
        # é‡Šæ”¾æœªæˆåŠŸå†™å…¥çš„ MRs
        self._release(mrs[status.get() :])
    else:
        # å¯¹äº ExternalMemoryRegionsï¼Œè½¬æ¢ä¸º tensors
        tensors = kv_tensors.to_tensors()
        status = self._l1_cache.put(prefix, query, tensors)
        kv_tensors.release()

    if not status.is_ok():
        return status
    return Status.ok(status.get() * self.block_ntokens)
```
- ä¼˜å…ˆå†™å…¥ L1 ç¼“å­˜
- L1 ç¼“å­˜çš„é©±é€ç­–ç•¥ä¼šè‡ªåŠ¨è§¦å‘ L2 åŒæ­¥ï¼ˆé€šè¿‡å›è°ƒï¼‰

**ç¬¬ 1528-1529 è¡Œï¼šç›´æ¥å†™å…¥ L2ï¼ˆå¦‚æœ L1 æœªå¯ç”¨ï¼‰**
```python
else:
    return self._l2_put(prefix, query, kv_tensors)
```
- å¦‚æœ L1 æœªå¯ç”¨ï¼Œç›´æ¥å†™å…¥ L2

---

### 5. `_l2_put_async()` - å¼‚æ­¥å†™å…¥ L2

è¿™æ˜¯å¼‚æ­¥å†™å…¥ L2 ç¼“å­˜çš„å®ç°ã€‚

```python
def _l2_put_async(
    self,
    prefix: KVCacheKeyTypes | None,
    query: KVCacheKeyTypes,
    value: (MemoryRegion | KVCacheHandle),
) -> Status:
```

#### é€è¡Œä»£ç è§£é‡Š

**ç¬¬ 971-993 è¡Œï¼šæ£€æŸ¥å¹¶å‘é…é¢**
```python
with self._lock:
    log_every_n_seconds(
        logger,
        logging.INFO,
        "l2_cache infight writes %d/quota %d",
        3,
        self._l2_inflight_writes,
        self._l2_inflight_quota,
    )
    if self._l2_inflight_quota <= self._l2_inflight_writes:
        # é…é¢å·²æ»¡ï¼Œæ‹’ç»å†™å…¥
        log_every_n_seconds(...)
        return Status(StatusCodes.DENIED)
    self._l2_inflight_writes += 1
```
- æ£€æŸ¥å½“å‰æ­£åœ¨è¿›è¡Œçš„å†™å…¥æ•°é‡
- å¦‚æœè¶…è¿‡é…é¢ï¼Œæ‹’ç»å†™å…¥ï¼ˆé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰

**ç¬¬ 995-1011 è¡Œï¼šå®šä¹‰å®Œæˆå›è°ƒ**
```python
def _done_callback(
    future: asyncio.Future,
    value: (MemoryRegion | KVCacheHandle),
) -> None:
    self._release([value])  # é‡Šæ”¾å†…å­˜åŒºåŸŸ

    with self._infight_cv:
        self._l2_inflight_writes -= 1
        self._infight_cv.notify_all()  # é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
    if not future.result().is_ok():
        log_every_n_seconds(
            logger,
            logging.WARNING,
            "Failed to write to l2_cache, error: %s",
            10,
            future.result().value,
        )
```
- å†™å…¥å®Œæˆæ—¶é‡Šæ”¾èµ„æº
- å‡å°‘å¹¶å‘è®¡æ•°å¹¶é€šçŸ¥ç­‰å¾…çš„çº¿ç¨‹
- è®°å½•é”™è¯¯æ—¥å¿—

**ç¬¬ 1013-1019 è¡Œï¼šæäº¤å¼‚æ­¥å†™å…¥ä»»åŠ¡**
```python
assert self._event_loop is not None
future = asyncio.run_coroutine_threadsafe(
    self._l2_cache.put(prefix, query, value), self._event_loop
)
future.add_done_callback(functools.partial(_done_callback, value=value))
return Status.ok(len(query))
```
- åœ¨äº‹ä»¶å¾ªç¯ä¸­æäº¤å¼‚æ­¥å†™å…¥ä»»åŠ¡
- æ·»åŠ å®Œæˆå›è°ƒ
- ç«‹å³è¿”å›æˆåŠŸï¼ˆå®é™…å†™å…¥æ˜¯å¼‚æ­¥çš„ï¼‰

---

## æ ¸å¿ƒç»„ä»¶è¯¦è§£

### 1. L1Cache - æœ¬åœ°ç¼“å­˜å±‚

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/l1/l1_cache.py`

**åŠŸèƒ½**:
- æä¾›å¿«é€Ÿçš„æœ¬åœ°å†…å­˜ç¼“å­˜ï¼ˆCPU æˆ– GPUï¼‰
- å®ç°å¤šç§é©±é€ç­–ç•¥ï¼ˆLRUã€FIFOã€S3FIFOï¼‰
- æ”¯æŒå›è°ƒæœºåˆ¶ï¼Œç”¨äºåŒæ­¥åˆ° L2

**å…³é”®æ–¹æ³•**:
- `put()`: å†™å…¥ç¼“å­˜ï¼Œè§¦å‘é©±é€ç­–ç•¥
- `acquire()`: è·å–ç¼“å­˜æ•°æ®
- `exists()`: æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
- `allocate()`: åˆ†é…å†…å­˜åŒºåŸŸ

**é©±é€ç­–ç•¥**:
- **LRU**: æœ€è¿‘æœ€å°‘ä½¿ç”¨ï¼Œé€‚åˆå¤§å¤šæ•°åœºæ™¯
- **FIFO**: å…ˆè¿›å…ˆå‡ºï¼Œç®€å•é«˜æ•ˆ
- **S3FIFO**: ä¸‰é˜Ÿåˆ— FIFOï¼Œå¹³è¡¡æ€§èƒ½å’Œå¤æ‚åº¦

---

### 2. L2Cache - è¿œç¨‹ç¼“å­˜å±‚

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/l2/l2_cache.py`

**åŠŸèƒ½**:
- æä¾›æŒä¹…åŒ–çš„è¿œç¨‹ç¼“å­˜å­˜å‚¨
- æ”¯æŒå¤šç§åç«¯ï¼ˆRocksDBã€InfiniStoreã€HPKVã€PRISã€EICï¼‰
- å¼‚æ­¥æ“ä½œï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹

**å…³é”®æ–¹æ³•**:
- `put()`: å¼‚æ­¥å†™å…¥ç¼“å­˜
- `get()`: å¼‚æ­¥è¯»å–ç¼“å­˜
- `exists()`: å¼‚æ­¥æ£€æŸ¥å­˜åœ¨æ€§
- `prefetch()`: é¢„å–æ•°æ®ï¼ˆå¦‚æœåç«¯æ”¯æŒï¼‰

**åç«¯è¿æ¥å™¨**:
- **RocksDB**: æœ¬åœ°æŒä¹…åŒ–å­˜å‚¨
- **InfiniStore**: åˆ†å¸ƒå¼ KV å­˜å‚¨
- **HPKV**: é«˜æ€§èƒ½ KV å­˜å‚¨
- **PRIS**: PRIS ç¼“å­˜æœåŠ¡
- **EIC**: åµŒå…¥å¼æ¨ç†ç¼“å­˜

---

### 3. TensorPoolAllocator - å†…å­˜åˆ†é…å™¨

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/memory/allocator.py`

**åŠŸèƒ½**:
- ç»Ÿä¸€ç®¡ç†å†…å­˜åˆ†é…å’Œé‡Šæ”¾
- ä½¿ç”¨å†…å­˜æ± å‡å°‘åˆ†é…å¼€é”€
- æ”¯æŒ CPU å’Œ GPU å†…å­˜

**å…³é”®æ–¹æ³•**:
- `alloc()`: åˆ†é…å†…å­˜åŒºåŸŸ
- `free()`: é‡Šæ”¾å†…å­˜åŒºåŸŸ
- `capacity_nbytes`: æ€»å®¹é‡
- `_used_nbytes`: å·²ä½¿ç”¨å®¹é‡

**å†…å­˜å¸ƒå±€**:
- **Slab**: å¤§å—è¿ç»­å†…å­˜
- **MemoryRegion**: ä» slab ä¸­åˆ†é…çš„åŒºåŸŸ
- **å¼•ç”¨è®¡æ•°**: è‡ªåŠ¨ç®¡ç†å†…å­˜ç”Ÿå‘½å‘¨æœŸ

---

### 4. KVCacheHandle - ç¼“å­˜å¥æŸ„

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/cache_handle.py`

**åŠŸèƒ½**:
- æä¾›é›¶æ‹·è´çš„ç¼“å­˜è®¿é—®æ¥å£
- å°è£…å†…å­˜åŒºåŸŸï¼Œæ”¯æŒå¼•ç”¨è®¡æ•°
- æ”¯æŒè½¬æ¢ä¸º PyTorch Tensor

**ç±»å‹**:
- `MemoryRegionKVCacheHandle`: åŸºäºå†…å­˜åŒºåŸŸçš„å¥æŸ„
- `GDRKVCacheHandle`: GPU Direct Read å¥æŸ„ï¼ˆé›¶æ‹·è´ï¼‰

**å…³é”®æ–¹æ³•**:
- `to_tensors()`: è½¬æ¢ä¸º PyTorch Tensor
- `release()`: é‡Šæ”¾èµ„æº
- `truncate()`: æˆªæ–­åˆ°æŒ‡å®šé•¿åº¦

---

### 5. Cache Hashable - ç¼“å­˜é”®

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/cache_hashable.py`

**åŠŸèƒ½**:
- æä¾›å¯å“ˆå¸Œçš„ç¼“å­˜é”®ç±»å‹
- æ”¯æŒ Token IDs å’Œ Block Hashes ä¸¤ç§é”®ç±»å‹

**ç±»å‹**:
- `TokenListView`: Token ID åˆ—è¡¨è§†å›¾
- `BlockHashes`: Block å“ˆå¸Œåˆ—è¡¨
- `KVCacheKey`: åŒ…å« prefix å’Œ query çš„å®Œæ•´é”®

---

### 6. MetaService - å…ƒæ•°æ®æœåŠ¡

**ä½ç½®**: `python/aibrix_kvcache/aibrix_kvcache/meta_service/`

**åŠŸèƒ½**:
- åœ¨åˆ†å¸ƒå¼åœºæ™¯ä¸­æä¾›å…ƒæ•°æ®ç®¡ç†
- æ”¯æŒ Redis åç«¯
- ç”¨äº L2 ç¼“å­˜çš„ placement ç­–ç•¥

---

## å…³é”®å‡½æ•°è¯¦è§£

### 1. `_use_double_get()` - åŒç¼“å­˜æŸ¥è¯¢å†³ç­–

```python
def _use_double_get(
    self, num_missing_blocks: int, num_total_blocks: int
) -> bool:
```

**åŠŸèƒ½**: å†³å®šæ˜¯å¦åŒæ—¶æŸ¥è¯¢ L1 å’Œ L2 ç¼“å­˜

**é€»è¾‘**:
- å¦‚æœ L2 æœªå¯ç”¨ï¼Œè¿”å› False
- å¦‚æœåªè®¾ç½®äº†æ•°é‡é˜ˆå€¼ï¼Œæ£€æŸ¥ç¼ºå¤±å—æ•°æ˜¯å¦ >= é˜ˆå€¼
- å¦‚æœåŒæ—¶è®¾ç½®äº†æ•°é‡å’Œæ¯”ä¾‹é˜ˆå€¼ï¼Œä¸¤è€…éƒ½è¦æ»¡è¶³

**ä¼˜åŒ–ç›®çš„**: é¿å…åœ¨ L1 å‘½ä¸­ç‡å¾ˆé«˜æ—¶ï¼Œä»ç„¶æŸ¥è¯¢ L2 é€ æˆçš„æ€§èƒ½æŸå¤±

---

### 2. `_l2_ingestion_callback()` - L2 åŒæ­¥å›è°ƒ

```python
def _l2_ingestion_callback(
    self,
    key: KVCacheKey,
    mr: MemoryRegion,
) -> Status:
```

**åŠŸèƒ½**: L1 ç¼“å­˜è§¦å‘æ—¶ï¼Œå°†æ•°æ®åŒæ­¥åˆ° L2

**è§¦å‘æ—¶æœº**:
- `HOT`: æ•°æ®å˜ä¸ºçƒ­æ•°æ®æ—¶
- `ALL`: æ¯æ¬¡å†™å…¥ L1 æ—¶
- `EVICT`: L1 é©±é€æ•°æ®æ—¶

---

### 3. `cache_chunk_keys()` - åˆ†å—é”®ç”Ÿæˆå™¨

```python
def cache_chunk_keys(
    self, prefix: KVCacheKeyTypes | None, query: KVCacheKeyTypes
) -> Iterator[Tuple[...]]:
```

**åŠŸèƒ½**: å°†é•¿åºåˆ—åˆ†å‰²æˆå¤šä¸ª chunkï¼Œæ¯ä¸ª chunk å¤§å°ä¸º `_chunk_size`

**è¿”å›**: è¿­ä»£å™¨ï¼Œæ¯æ¬¡è¿”å› (chunk_prefix, chunk_tokens, next_tokens, all_tokens)

**ç”¨é€”**: 
- æ”¯æŒåˆ†å—å¤„ç†é•¿åºåˆ—
- æ”¯æŒé¢„å–ä¸‹ä¸€ä¸ª chunk

---

### 4. `flush()` - åˆ·æ–°ç¼“å­˜

```python
def flush(self) -> Status:
```

**åŠŸèƒ½**: ç­‰å¾…æ‰€æœ‰å¼‚æ­¥ L2 å†™å…¥å®Œæˆ

**å®ç°**:
- ä½¿ç”¨æ¡ä»¶å˜é‡ç­‰å¾… `_l2_inflight_writes` é™ä¸º 0
- è¶…æ—¶æ—¶é—´ 60 ç§’

**ç”¨é€”**: åœ¨å…³é—­å‰ç¡®ä¿æ‰€æœ‰æ•°æ®å·²æŒä¹…åŒ–

---

### 5. `close()` - å…³é—­ç®¡ç†å™¨

```python
def close(self) -> None:
```

**åŠŸèƒ½**: ä¼˜é›…å…³é—­æ‰€æœ‰ç»„ä»¶

**æ­¥éª¤**:
1. è°ƒç”¨ `flush()` ç­‰å¾…å¼‚æ­¥æ“ä½œå®Œæˆ
2. åœæ­¢äº‹ä»¶å¾ªç¯
3. ç­‰å¾…çº¿ç¨‹ç»“æŸ
4. å…³é—­çº¿ç¨‹æ± æ‰§è¡Œå™¨
5. åˆ é™¤ L1 å’Œ L2 ç¼“å­˜

---

## æ¶æ„å›¾

```mermaid
flowchart TB
    subgraph Client["æ¨ç†å¼•æ“ (vLLM/SGLang)"]
        Engine["æ¨ç†è¯·æ±‚"]
    end

    subgraph KVCacheManager["KV Cache Manager"]
        subgraph API["å…¬å…± API å±‚"]
            Acquire["acquire()<br/>è·å–ç¼“å­˜"]
            Put["put()<br/>å†™å…¥ç¼“å­˜"]
            Exists["exists()<br/>æ£€æŸ¥å­˜åœ¨"]
            Delete["delete()<br/>åˆ é™¤ç¼“å­˜"]
            Allocate["allocate_for()<br/>åˆ†é…å†…å­˜"]
        end

        subgraph Core["æ ¸å¿ƒé€»è¾‘å±‚"]
            AcquireImpl["_acquire_impl()<br/>â€¢ L1 æŸ¥è¯¢<br/>â€¢ L2 æŸ¥è¯¢<br/>â€¢ åŒç¼“å­˜ç­–ç•¥"]
            PutImpl["put() å®ç°<br/>â€¢ L1 å†™å…¥<br/>â€¢ L2 åŒæ­¥"]
            DoubleGet["_use_double_get()<br/>åŒç¼“å­˜å†³ç­–"]
        end

        subgraph L1["L1 ç¼“å­˜å±‚"]
            L1Cache["L1Cache<br/>â€¢ LRU/FIFO/S3FIFO<br/>â€¢ CPU/GPU å†…å­˜<br/>â€¢ å¿«é€Ÿè®¿é—®"]
            EvictionPolicy["é©±é€ç­–ç•¥<br/>â€¢ è‡ªåŠ¨é©±é€<br/>â€¢ å›è°ƒè§¦å‘"]
        end

        subgraph L2["L2 ç¼“å­˜å±‚"]
            L2Cache["L2Cache<br/>â€¢ å¼‚æ­¥æ“ä½œ<br/>â€¢ æŒä¹…åŒ–å­˜å‚¨"]
            Connector["åç«¯è¿æ¥å™¨<br/>â€¢ RocksDB<br/>â€¢ InfiniStore<br/>â€¢ HPKV<br/>â€¢ PRIS<br/>â€¢ EIC"]
            AsyncLoop["å¼‚æ­¥äº‹ä»¶å¾ªç¯<br/>â€¢ ç‹¬ç«‹çº¿ç¨‹<br/>â€¢ éé˜»å¡æ“ä½œ"]
        end

        subgraph Memory["å†…å­˜ç®¡ç†å±‚"]
            Allocator["TensorPoolAllocator<br/>â€¢ å†…å­˜æ± <br/>â€¢ å¼•ç”¨è®¡æ•°<br/>â€¢ Slab ç®¡ç†"]
            Handle["KVCacheHandle<br/>â€¢ é›¶æ‹·è´<br/>â€¢ ç”Ÿå‘½å‘¨æœŸç®¡ç†"]
        end

        subgraph Metrics["ç›‘æ§å±‚"]
            MetricsCollector["KVCacheMetrics<br/>â€¢ å‘½ä¸­ç‡<br/>â€¢ å»¶è¿Ÿç»Ÿè®¡<br/>â€¢ èµ„æºä½¿ç”¨"]
        end
    end

    subgraph Storage["å­˜å‚¨åç«¯"]
        RocksDB["RocksDB"]
        InfiniStore["InfiniStore"]
        HPKV["HPKV"]
        Other["å…¶ä»–åç«¯..."]
    end

    Engine --> API
    API --> Core
    Core --> L1
    Core --> L2
    L1 --> Memory
    L2 --> Memory
    L1 --> EvictionPolicy
    EvictionPolicy -.->|"å›è°ƒ"| L2
    L2 --> Connector
    Connector --> Storage
    L2 --> AsyncLoop
    Core --> Metrics
    Memory --> Handle

    style KVCacheManager fill:#e1f5fe
    style L1 fill:#fff3e0
    style L2 fill:#e8f5e9
    style Memory fill:#fce4ec
    style Metrics fill:#f3e5f5
```

---

## ç±»å›¾

```mermaid
classDiagram
    class KVCacheManager {
        <<abstract>>
        +config: KVCacheConfig
        +block_spec: KVCacheBlockSpec
        +block_ntokens: int
        +acquire() Status[Tuple[int, KVCacheHandle]]
        +get() Status[int]
        +put() Status[int]
        +exists() Status[int]
        +delete() Status
        +allocate_for() Status[KVCacheHandle]
        +prefetch() None
        +close() None
        +metrics: KVCacheMetrics
    }

    class BaseKVCacheManager {
        -_l1_cache: L1Cache
        -_l2_cache: L2Cache
        -_allocator: TensorPoolAllocator
        -_executor: Executor
        -_event_loop: asyncio.AbstractEventLoop
        -_thread: threading.Thread
        -_metrics: KVCacheMetrics
        -_ms: MetaService
        -_lock: threading.Lock
        -_infight_cv: threading.Condition
        +_acquire_impl() Status[Sequence[MemoryRegion]]
        +_get_impl() Status[int]
        +_exists_impl() Status[int]
        +_l2_put() Status
        +_l2_put_async() Status
        +_l2_put_sync() Status
        +_l2_ingestion_callback() Status
        +_use_double_get() bool
        +_release() None
        +cache_chunk_keys() Iterator
        +flush() Status
    }

    class GroupAwareKVCacheManager {
        +process_group: dist.ProcessGroup
        +world_size: int
        +rank: int
        -_coll_tensor: torch.Tensor
        +_group_aware_acquire_impl() Status[Tuple[int, Sequence[MemoryRegion]]]
        +acquire() Status[Tuple[int, KVCacheHandle]]
        +get() Status[int]
    }

    class L1Cache {
        -_eviction_policy: BaseEvictionPolicy
        -allocator: TensorPoolAllocator
        -capacity_nbytes: int
        +put() Status[int]
        +acquire() Status[Sequence[MemoryRegion]]
        +exists() Status[int]
        +delete() Status
        +allocate() Status[Sequence[MemoryRegion]]
        +set_on_put_callback() None
        +set_on_evict_callback() None
        +set_on_hot_access_callback() None
    }

    class L2Cache {
        -_backend: Connector
        -_executor: Executor
        -key_builder: KeyBuilder
        +put() Status
        +get() Status
        +exists() Status[int]
        +delete() Status
        +prefetch() Status
        +open() Status
        +close() Status
        +register_slabs() Status
    }

    class TensorPoolAllocator {
        -slabs: List[torch.Tensor]
        -capacity_nbytes: int
        -_used_nbytes: int
        +alloc() Status[Sequence[MemoryRegion]]
        +free() None
    }

    class KVCacheHandle {
        <<abstract>>
        +memory_regions: Sequence[MemoryRegion]
        +to_tensors() Sequence[torch.Tensor]
        +release() None
        +truncate() None
    }

    class MemoryRegionKVCacheHandle {
        -_mrs: Sequence[MemoryRegion]
        -_block_dtype: torch.dtype
        -_block_shape: Tuple[int, ...]
    }

    class KVCacheMetrics {
        +l1: L1CacheMetrics
        +l2: L2CacheMetrics
        +mgr: MetricRecorder
    }

    class MetaService {
        <<abstract>>
        +open() Status
        +close() Status
    }

    class Connector {
        <<abstract>>
        +put() Status
        +get() Status
        +exists() Status
        +delete() Status
        +prefetch() None
        +register_slabs() Status
    }

    KVCacheManager <|-- BaseKVCacheManager
    BaseKVCacheManager <|-- GroupAwareKVCacheManager
    BaseKVCacheManager *-- L1Cache
    BaseKVCacheManager *-- L2Cache
    BaseKVCacheManager *-- TensorPoolAllocator
    BaseKVCacheManager *-- KVCacheMetrics
    BaseKVCacheManager ..> MetaService
    L2Cache *-- Connector
    L1Cache *-- TensorPoolAllocator
    BaseKVCacheManager ..> KVCacheHandle
    KVCacheHandle <|-- MemoryRegionKVCacheHandle
    L2Cache ..> KeyBuilder
```

---

## æ€»ç»“

### ä½œç”¨å’ŒåŠŸèƒ½

**KV Cache Manager** æ˜¯ AIBrix KV Cache Offloading Framework çš„æ ¸å¿ƒç»„ä»¶ï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

1. **ä¸¤çº§ç¼“å­˜ç®¡ç†**
   - **L1 ç¼“å­˜**: å¿«é€Ÿæœ¬åœ°å†…å­˜ç¼“å­˜ï¼ˆCPU/GPUï¼‰ï¼Œæä¾›æ¯«ç§’çº§è®¿é—®
   - **L2 ç¼“å­˜**: æŒä¹…åŒ–è¿œç¨‹ç¼“å­˜ï¼ˆRocksDB/InfiniStore ç­‰ï¼‰ï¼Œæä¾›å¤§å®¹é‡å­˜å‚¨

2. **æ™ºèƒ½ç¼“å­˜ç­–ç•¥**
   - **é€‰æ‹©æ€§å¸è½½**: æ ¹æ®é…ç½®ï¼ˆHOT/ALL/EVICTï¼‰å†³å®šå“ªäº›æ•°æ®åŒæ­¥åˆ° L2
   - **åŒç¼“å­˜æŸ¥è¯¢**: æ ¹æ®é˜ˆå€¼æ™ºèƒ½å†³å®šæ˜¯å¦åŒæ—¶æŸ¥è¯¢ L1 å’Œ L2
   - **è‡ªåŠ¨é¢„å–**: æ”¯æŒé¢„å–ä¸‹ä¸€ä¸ª chunk çš„æ•°æ®

3. **å†…å­˜ç®¡ç†**
   - **ç»Ÿä¸€åˆ†é…å™¨**: ä½¿ç”¨ TensorPoolAllocator ç»Ÿä¸€ç®¡ç†å†…å­˜
   - **å¼•ç”¨è®¡æ•°**: è‡ªåŠ¨ç®¡ç†å†…å­˜ç”Ÿå‘½å‘¨æœŸ
   - **é›¶æ‹·è´**: æ”¯æŒ GPU Direct Readï¼Œå‡å°‘æ•°æ®æ‹·è´

4. **æ€§èƒ½ä¼˜åŒ–**
   - **å¼‚æ­¥æ“ä½œ**: L2 æ“ä½œå®Œå…¨å¼‚æ­¥ï¼Œä¸é˜»å¡ä¸»çº¿ç¨‹
   - **å¹¶å‘æ§åˆ¶**: é™åˆ¶ L2 å†™å…¥å¹¶å‘æ•°ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
   - **åˆ†å—å¤„ç†**: æ”¯æŒé•¿åºåˆ—çš„åˆ†å—å¤„ç†

### åœ¨ç³»ç»Ÿä¸­çš„è§’è‰²

1. **æ¨ç†å¼•æ“é›†æˆå±‚**
   - ä½œä¸º vLLMã€SGLang ç­‰æ¨ç†å¼•æ“çš„ KV ç¼“å­˜åç«¯
   - æä¾›ç»Ÿä¸€çš„ç¼“å­˜æ¥å£ï¼Œéšè—åº•å±‚å®ç°ç»†èŠ‚

2. **ç¼“å­˜å¸è½½æœåŠ¡**
   - å°† GPU å†…å­˜ä¸­çš„ KV ç¼“å­˜å¸è½½åˆ° CPU å†…å­˜æˆ–è¿œç¨‹å­˜å‚¨
   - æ”¯æŒè·¨å¼•æ“çš„ KV ç¼“å­˜å¤ç”¨

3. **æ€§èƒ½ä¼˜åŒ–ç»„ä»¶**
   - é€šè¿‡ç¼“å­˜å‘½ä¸­å‡å°‘é‡å¤è®¡ç®—
   - é€šè¿‡é€‰æ‹©æ€§å¸è½½ä¼˜åŒ–ç½‘ç»œå¸¦å®½ä½¿ç”¨

### ä»£ç è®¾è®¡ç‰¹ç‚¹

1. **åˆ†å±‚æ¶æ„**
   - **æŠ½è±¡å±‚**: `KVCacheManager` å®šä¹‰ç»Ÿä¸€æ¥å£
   - **å®ç°å±‚**: `BaseKVCacheManager` æä¾›åŸºç¡€å®ç°
   - **æ‰©å±•å±‚**: `GroupAwareKVCacheManager` æ”¯æŒåˆ†å¸ƒå¼åœºæ™¯

2. **ç»„ä»¶åŒ–è®¾è®¡**
   - L1 å’Œ L2 ç¼“å­˜ç‹¬ç«‹å®ç°ï¼Œå¯å•ç‹¬å¯ç”¨
   - åç«¯è¿æ¥å™¨å¯æ’æ‹”ï¼Œæ”¯æŒå¤šç§å­˜å‚¨åç«¯
   - é©±é€ç­–ç•¥å¯é…ç½®ï¼Œæ”¯æŒå¤šç§ç®—æ³•

3. **å¼‚æ­¥ç¼–ç¨‹æ¨¡å‹**
   - ä½¿ç”¨ asyncio å¤„ç† L2 ç¼“å­˜çš„å¼‚æ­¥æ“ä½œ
   - ç‹¬ç«‹äº‹ä»¶å¾ªç¯çº¿ç¨‹ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
   - ä½¿ç”¨ Future å’Œå›è°ƒå¤„ç†å¼‚æ­¥ç»“æœ

4. **èµ„æºç®¡ç†**
   - RAII æ¨¡å¼ï¼šé€šè¿‡ `__init__` å’Œ `close()` ç®¡ç†èµ„æº
   - å¼•ç”¨è®¡æ•°ï¼šè‡ªåŠ¨ç®¡ç†å†…å­˜åŒºåŸŸç”Ÿå‘½å‘¨æœŸ
   - æ¡ä»¶å˜é‡ï¼šåè°ƒå¼‚æ­¥æ“ä½œçš„å®Œæˆ

5. **å¯è§‚æµ‹æ€§**
   - å®Œæ•´çš„æ€§èƒ½æŒ‡æ ‡æ”¶é›†ï¼ˆå‘½ä¸­ç‡ã€å»¶è¿Ÿã€èµ„æºä½¿ç”¨ï¼‰
   - NVTX èŒƒå›´æ ‡è®°ï¼Œæ”¯æŒæ€§èƒ½åˆ†æå·¥å…·
   - è¯¦ç»†çš„æ—¥å¿—è®°å½•

6. **é”™è¯¯å¤„ç†**
   - ä½¿ç”¨ `Status` ç±»å‹ç»Ÿä¸€é”™è¯¯å¤„ç†
   - è¶…æ—¶æ§åˆ¶é˜²æ­¢é•¿æ—¶é—´é˜»å¡
   - ä¼˜é›…é™çº§ï¼šL2 å¤±è´¥æ—¶ä»å¯ä½¿ç”¨ L1

### è®¾è®¡æ¨¡å¼

1. **ç­–ç•¥æ¨¡å¼**: é©±é€ç­–ç•¥ã€placement ç­–ç•¥ã€é”®æ„å»ºç­–ç•¥
2. **å·¥å‚æ¨¡å¼**: Connector.create(), KeyBuilder.create()
3. **è§‚å¯Ÿè€…æ¨¡å¼**: L1 åˆ° L2 çš„å›è°ƒæœºåˆ¶
4. **é€‚é…å™¨æ¨¡å¼**: ä¸åŒåç«¯è¿æ¥å™¨çš„ç»Ÿä¸€æ¥å£

### æ€§èƒ½è€ƒè™‘

1. **å‡å°‘å†…å­˜æ‹·è´**: ä½¿ç”¨ MemoryRegion å’Œå¼•ç”¨è®¡æ•°
2. **å¼‚æ­¥æ“ä½œ**: L2 æ“ä½œä¸é˜»å¡ä¸»çº¿ç¨‹
3. **æ™ºèƒ½æŸ¥è¯¢**: åŒç¼“å­˜ç­–ç•¥é¿å…ä¸å¿…è¦çš„ L2 æŸ¥è¯¢
4. **æ‰¹é‡æ“ä½œ**: æ”¯æŒæ‰¹é‡ get/put æ“ä½œ
5. **é¢„å–æœºåˆ¶**: æ”¯æŒé¢„å–ä¸‹ä¸€ä¸ª chunk

---

## å…³é”®é…ç½®å‚æ•°

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `AIBRIX_KV_CACHE_OL_L1_CACHE_ENABLED` | å¯ç”¨ L1 ç¼“å­˜ | true |
| `AIBRIX_KV_CACHE_OL_L1_CACHE_CAPACITY_GB` | L1 ç¼“å­˜å®¹é‡ï¼ˆGBï¼‰ | - |
| `AIBRIX_KV_CACHE_OL_L1_CACHE_EVICTION_POLICY` | L1 é©±é€ç­–ç•¥ | LRU |
| `AIBRIX_KV_CACHE_OL_L2_CACHE_BACKEND` | L2 åç«¯åç§° | "" |
| `AIBRIX_KV_CACHE_OL_L2_CACHE_INGESTION_TYPE` | L2 åŒæ­¥ç­–ç•¥ | EVICT |
| `AIBRIX_KV_CACHE_OL_CHUNK_SIZE` | åˆ†å—å¤§å° | - |
| `AIBRIX_KV_CACHE_OL_DOUBLE_GET_THRESHOLD` | åŒç¼“å­˜æŸ¥è¯¢é˜ˆå€¼ | - |
| `AIBRIX_KV_CACHE_OL_DEVICE` | å­˜å‚¨è®¾å¤‡ | cpu |

---

## ä½¿ç”¨ç¤ºä¾‹

```python
from aibrix_kvcache import KVCacheManager, KVCacheConfig
from aibrix_kvcache.spec import KVCacheBlockSpec, ModelSpec

# åˆ›å»ºé…ç½®
config = KVCacheConfig(
    block_spec=KVCacheBlockSpec(...),
    model_spec=ModelSpec(...),
    multi_threaded=True
)

# åˆ›å»ºç®¡ç†å™¨
manager = BaseKVCacheManager(config)

# å†™å…¥ç¼“å­˜
prefix = TokenListView([1, 2, 3])
query = TokenListView([4, 5, 6, 7])
kv_tensors = allocate_for(prefix, query)
status = manager.put(prefix, query, kv_tensors)

# è·å–ç¼“å­˜
status, handle = manager.acquire(prefix, query)
if status.is_ok():
    tokens_count, cache_handle = status.get()
    tensors = cache_handle.to_tensors()
    # ä½¿ç”¨ tensors...
    cache_handle.release()

# å…³é—­
manager.close()
```

---

## æ€»ç»“

**KV Cache Manager** æ˜¯ä¸€ä¸ªè®¾è®¡ç²¾è‰¯ã€åŠŸèƒ½å®Œå–„çš„ç¼“å­˜ç®¡ç†ç³»ç»Ÿï¼Œå®ƒé€šè¿‡ä¸¤çº§ç¼“å­˜æ¶æ„ã€æ™ºèƒ½ç­–ç•¥å’Œå¼‚æ­¥æ“ä½œï¼Œä¸ºæ¨ç†å¼•æ“æä¾›äº†é«˜æ•ˆçš„ KV ç¼“å­˜å¸è½½èƒ½åŠ›ã€‚å…¶æ¨¡å—åŒ–è®¾è®¡å’Œä¸°å¯Œçš„é…ç½®é€‰é¡¹ï¼Œä½¿å…¶èƒ½å¤Ÿé€‚åº”å„ç§éƒ¨ç½²åœºæ™¯å’Œæ€§èƒ½éœ€æ±‚ã€‚

